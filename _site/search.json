[
  {
    "objectID": "Pima_Challenge_Explore.html",
    "href": "Pima_Challenge_Explore.html",
    "title": "Pima Machine Learning Challenge – Exploratory Preprocessing (R & Python)",
    "section": "",
    "text": "Pima ML Challenge\n\nExplore preprocessing choices\n\n\n\n\n1. Load and inspect the data\nUse the Pima Indians Diabetes dataset and work with:\n\npredictors: age, glucose, insulin\noutcome: pedigree\n\nCreate a train/test split and reuse it for all experiments.\nTools you will need:\n\nR: initial_split(), training(), testing()\nPython: train_test_split() from scikit‑learn\n\n\n\n\n2. Baseline model (no preprocessing)\nFit a simple regression model:\n\nOutcome: pedigree\nPredictors: age + glucose + insulin + diabetes\n\nGoal:\nGet a baseline MAE against which all your later models will be compared.\nTools:\n\nR:\n\nmodel: linear_reg(engine = \"lm\")\n\nevaluation: mae()\n\n\nPython:\n\nmodel: LinearRegression()\n\nevaluation: mean_absolute_error()\n\n\nResources: tidymodels.org / scikit-learn.org\n\n\n\n3. Mean imputation (leak-free)\nSome insulin and glucose values are missing.\nTry mean imputation, but do it correctly:\n\nmean should be computed from the training data only\napply that mean to both training and test sets\n\nTools:\n\nR (recipes):\n\nimputation step to explore: step_impute_mean()\n\n\nPython:\n\nSimpleImputer(strategy=\"mean\")\n\n\nTask:\nCompute MAE and compare with the baseline.\n\n\n\n4. Try alternative imputation methods\nExperiment with different imputation choices:\n\nmedian\n\nconstant value\n\noptional: bagged tree imputation (R)\n\nTools:\n\nR:\n\nstep_impute_median()\n\nstep_impute_bagged()\n\n\nPython:\n\nSimpleImputer(strategy=\"median\")\n\nSimpleImputer(strategy=\"constant\")\n\n\nTask:\nWhich imputer gives the best MAE?\nWhich one behaves unexpectedly?\n\n\n\n5. Log-transform insulin (after imputation)\nCreate a new variable:\n[ = () ]\nDo this after imputation to avoid problems with missing values or zeros.\nTools:\n\nR: step_log()\n\nPython: FunctionTransformer or manual np.log1p()\n\nTask:\nCompare MAE between using insulin vs. insulin_log.\n\n\n\n6. Categorical age + one-hot encoding\nTurn age into three categories:\n\n&lt; 30\n30−60\n&gt; 60\n\nThen convert that categorical variable into dummy variables.\nTools:\n\nR:\n\ncut age into categories (mutate() or step_cut())\n\nstep_dummy() for one-hot encoding\n\n\nPython:\n\npd.cut()\n\nOneHotEncoder()\n\n\nTask:\nCheck out coefficients of the model created, how do they differ? Are you identifying any issues when splitting the data?\n\n\n\n7. Build your own full pipeline\nCombine any of the following:\n\nyour preferred imputation method\n\nlog-transform\n\nscaling\n\nage category & one‑hot encoding\n\nadditional engineered features if you want\n\nTools:\n\nR:\n\nrecipe() + steps of your choice\n\nbuild model with a workflow\n\nevaluate with last_fit() if you want — or evaluate manually\n\n\nPython:\n\nColumnTransformer()\n\nPipeline()\n\nevaluate with MAE\n\n\nTask:\nCreate your best-performing MAE model.\n\n\n\n8. Compare all your models\nCreate a small results table summarising:\n\nbaseline MAE\n\neach imputation MAE\n\nlog-transform MAE\n\nage category MAE\n\nyour final best model MAE\n\nAdd a short reflection:\n\nWhich transformation improved performance?\nWhich added complexity for no benefit?\nWhat does this suggest about the dataset?\n\n\n\n\nResources You May Want to Explore\n\nR\n\nhttps://www.tidymodels.org/start/recipes/\n\n\n\nPython\n\nhttps://scikit-learn.org/stable/modules/impute.html\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n\nhttps://scikit-learn.org/stable/modules/compose.ColumnTransformer.html\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n\nExtra: This dataset has been widely studied, check out this python pipeline (until Pipeline factory in chunk 60) for a good preprocessing and EDA example\n\nhttps://github.com/tarekmasryo/pima-diabetes-pipeline/blob/main/diabetes-prediction-from-eda-to-production.ipynb\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EDA and Pre-Processing",
      "Pima Machine Learning Challenge – Exploratory Preprocessing (R & Python)"
    ]
  },
  {
    "objectID": "pima_imputation_leakage.html",
    "href": "pima_imputation_leakage.html",
    "title": "Pima Imputation → Leak vs Leak-free (R)",
    "section": "",
    "text": "Codelibrary(tidyverse)\nlibrary(janitor)\nlibrary(tidymodels)\n\ntheme_set(theme_minimal())\nset.seed(123)",
    "crumbs": [
      "EDA and Pre-Processing",
      "Pima Imputation → Leak vs Leak-free (R)"
    ]
  },
  {
    "objectID": "pima_imputation_leakage.html#imputation-leakage-with-insulin-no-scaling",
    "href": "pima_imputation_leakage.html#imputation-leakage-with-insulin-no-scaling",
    "title": "Pima Imputation → Leak vs Leak-free (R)",
    "section": "Imputation leakage with insulin (no scaling)",
    "text": "Imputation leakage with insulin (no scaling)\nWe now look at mean imputation of insulin:\n\n\nOutcome: pedigree\n\n\nPredictors: age, insulin_imp\n\nWe compare:\n\n❌ WRONG: mean for imputation computed using all data (leakage)\n✅ RIGHT: mean for imputation computed using training data only\n\n\n\n\n\nCodedata(\"PimaIndiansDiabetes2\", package = \"mlbench\")\n\npima_imp &lt;- PimaIndiansDiabetes2 %&gt;%\n  clean_names() %&gt;%\n  select(age, insulin, pedigree) %&gt;%\n  filter(!is.na(pedigree))  # outcome must be present\n\nsummary(pima_imp)\n\n      age           insulin          pedigree     \n Min.   :21.00   Min.   : 14.00   Min.   :0.0780  \n 1st Qu.:24.00   1st Qu.: 76.25   1st Qu.:0.2437  \n Median :29.00   Median :125.00   Median :0.3725  \n Mean   :33.24   Mean   :155.55   Mean   :0.4719  \n 3rd Qu.:41.00   3rd Qu.:190.00   3rd Qu.:0.6262  \n Max.   :81.00   Max.   :846.00   Max.   :2.4200  \n                 NA's   :374                      \n\n\n1. WRONG pipeline: impute using global mean (leakage)\nHere we:\n\nCompute the global mean insulin using all rows.\nImpute missing insulin values with this global mean.\nThen split into train/test.\nFit pedigree ~ age + insulin_imp and evaluate MAE.\n\n\nCode# 1. Global mean (leaky: uses all data)\nmean_all_insulin &lt;- mean(pima_imp$insulin, na.rm = TRUE)\nmean_all_insulin\n\n[1] 155.5482\n\n\n\nCode# 2. Impute WHOLE dataset with global mean (before splitting)\npima_imp_wrong &lt;- pima_imp %&gt;%\n  mutate(\n    insulin_imp = ifelse(is.na(insulin), mean_all_insulin, insulin)\n  )\n\nsummary(pima_imp_wrong$insulin_imp)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   14.0   121.5   155.5   155.5   155.5   846.0 \n\n\n\nCode# 3. Train–test split AFTER imputation (still leaky)\nset.seed(123)\nsplit_wrong &lt;- initial_split(pima_imp_wrong, prop = 0.7)\n\ntrain_wrong &lt;- training(split_wrong)\ntest_wrong  &lt;- testing(split_wrong)\n\nnrow(train_wrong); nrow(test_wrong)\n\n[1] 537\n\n\n[1] 231\n\n\n\nCode# 4. Fit linear regression and compute MAE (WRONG)\nped_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\nfit_wrong_imp &lt;- ped_model %&gt;%\n  fit(pedigree ~ age + insulin_imp, data = train_wrong)\n\ntidy(fit_wrong_imp)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept) 0.369     0.0487       7.57  1.60e-13\n2 age         0.00115   0.00126      0.912 3.62e- 1\n3 insulin_imp 0.000467  0.000172     2.72  6.75e- 3\n\n\n\nCoderesults_wrong_imp &lt;- predict(fit_wrong_imp, new_data = test_wrong) %&gt;%\n  bind_cols(test_wrong)\n\nmae_wrong_imp &lt;- mae(\n  data     = results_wrong_imp,\n  truth    = pedigree,\n  estimate = .pred\n)\n\nmae_wrong_imp\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 mae     standard       0.235\n\n\n2. RIGHT pipeline: impute using training mean only (no leakage)\nNow we:\n\nSplit the original (unimputed) data into train/test.\nCompute mean insulin using training data only.\nImpute train and test using this training mean.\nFit the same model and compute MAE.\n\n\nCode# 1. Train–test split on RAW data\nset.seed(123)\nsplit_right &lt;- initial_split(pima_imp, prop = 0.7)\n\ntrain_right &lt;- training(split_right)\ntest_right  &lt;- testing(split_right)\n\nnrow(train_right); nrow(test_right)\n\n[1] 537\n\n\n[1] 231\n\n\n\nCode# 2. Training-only mean for insulin (correct)\nmean_tr_insulin &lt;- mean(train_right$insulin, na.rm = TRUE)\nmean_tr_insulin\n\n[1] 155.3705\n\n\n\nCode# 3. Impute train and test using TRAIN mean\ntrain_right_imp &lt;- train_right %&gt;%\n  mutate(\n    insulin_imp = ifelse(is.na(insulin), mean_tr_insulin, insulin)\n  )\n\ntest_right_imp &lt;- test_right %&gt;%\n  mutate(\n    insulin_imp = ifelse(is.na(insulin), mean_tr_insulin, insulin)\n  )\n\nsummary(train_right_imp$insulin_imp)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   14.0   120.0   155.4   155.4   155.4   846.0 \n\nCodesummary(test_right_imp$insulin_imp)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   15.0   125.5   155.4   155.7   155.4   600.0 \n\n\n\nCode# 4. Fit linear regression and compute MAE (RIGHT)\nfit_right_imp &lt;- ped_model %&gt;%\n  fit(pedigree ~ age + insulin_imp, data = train_right_imp)\n\ntidy(fit_right_imp)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept) 0.369     0.0487       7.57  1.60e-13\n2 age         0.00115   0.00126      0.912 3.62e- 1\n3 insulin_imp 0.000468  0.000172     2.72  6.68e- 3\n\n\n\nCoderesults_right_imp &lt;- predict(fit_right_imp, new_data = test_right_imp) %&gt;%\n  bind_cols(test_right_imp)\n\nmae_right_imp &lt;- mae(\n  data     = results_right_imp,\n  truth    = pedigree,\n  estimate = .pred\n)\n\nmae_right_imp\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 mae     standard       0.235\n\n\n3. Compare MAE: imputation with vs without leakage\n\nCodetibble(\n  pipeline = c(\"WRONG: impute with global mean (leakage)\",\n               \"RIGHT: impute with training mean only\"),\n  MAE = c(mae_wrong_imp$.estimate,\n          mae_right_imp$.estimate)\n)\n\n# A tibble: 2 × 2\n  pipeline                                   MAE\n  &lt;chr&gt;                                    &lt;dbl&gt;\n1 WRONG: impute with global mean (leakage) 0.235\n2 RIGHT: impute with training mean only    0.235",
    "crumbs": [
      "EDA and Pre-Processing",
      "Pima Imputation → Leak vs Leak-free (R)"
    ]
  },
  {
    "objectID": "EDA_Practical3.html",
    "href": "EDA_Practical3.html",
    "title": "Data Transformation - Python",
    "section": "",
    "text": "We are using both Pandas (data loading, processing, transformation and manipulation) and Scikit-learn (example data source, ML and statistical analysis)",
    "crumbs": [
      "EDA and Pre-Processing",
      "Data Transformation - Python"
    ]
  },
  {
    "objectID": "EDA_Practical3.html#data-scaling-and-normalization",
    "href": "EDA_Practical3.html#data-scaling-and-normalization",
    "title": "Data Transformation - Python",
    "section": "Data Scaling and Normalization",
    "text": "Data Scaling and Normalization\n\nDifferent Types of Normalization.\n\nData Set Used :\nBreast Cancer Wisconsin (Diagnostic) Data Set\nFeatures are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: “Robust Linear Programming Discrimination of Two Linearly Inseparable Sets”, Optimization Methods and Software 1, 1992, 23-34].\n\nlibrary(reticulate)\n\n# one-off setup (if you haven't done it yet)\n# install_miniconda()\n\n##conda_create(\n##  envname = \"hds-python\",\n##  python_version = \"3.11\",\n##  packages = c(\"numpy\", \"pandas\", \"matplotlib\", \"seaborn\", \"scikit-learn\")\n##)\n\nuse_condaenv(\"hds-python\", required = TRUE)\n#py_config()\n\n#conda_install(\"hds-python\", c(\"jupyter\", \"plotly\"))\n\n\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom scipy import stats\nimport seaborn as sns\nfrom sklearn import datasets\nimport matplotlib.pyplot as plt\n\n\n# Load the dataset\ndata = datasets.load_breast_cancer()\ndf = pd.DataFrame(data.data, columns=data.feature_names)\n\n\n# Let's look at the first few rows of the dataframe\nprint(df.head())\n\n   mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n0        17.99         10.38  ...          0.4601                  0.11890\n1        20.57         17.77  ...          0.2750                  0.08902\n2        19.69         21.25  ...          0.3613                  0.08758\n3        11.42         20.38  ...          0.6638                  0.17300\n4        20.29         14.34  ...          0.2364                  0.07678\n\n[5 rows x 30 columns]\n\n\n\n# Let's plot the data before transformation\nplt.figure(figsize=(10, 6))\nsns.kdeplot(data=df)\nplt.title(\"Non-normalised data\")\nplt.show()\n\n\n\n\n\n\n\nStrategy 1 : Min-Max scaling\nMin-Max scaling: This transformation scales and translates each feature individually such that it is in the range [0, 1]. The transformed data is stored in df_minmax.\n\n#### Strategy 1 : Min-Max scaling\nscaler = preprocessing.MinMaxScaler(feature_range=(0,100))\ndf_minmax = pd.DataFrame(scaler.fit_transform(df), columns=data.feature_names)\n#print(\"\\nAfter Min-Max Scaling:\\n\", df_minmax.head())\n\n\n# Let's plot the data after min-max scaling\nplt.figure(figsize=(10, 6))\nsns.kdeplot(data=df_minmax)\nplt.title(\"After Min-Max Scaling\")\nplt.show()\n\n\n\n\n\n\n\nLog transformation:\nThis transformation applies the natural logarithm to each value in the DataFrame. This is often used when the data is highly skewed, as it can help to make the data more “normal” (i.e., more closely approximate a normal distribution). The transformed data is stored in df_log.\n\n# Log Transformation\ndf_log = df.apply(np.log)\ndf_log = df_log.replace([np.inf, -np.inf], np.nan)\ndf_log = df_log.dropna()\nprint(\"\\nAfter Log Transformation:\\n\", df_log.head())\n\n\nAfter Log Transformation:\n    mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n0     2.889816      2.339881  ...       -0.776311                -2.129472\n1     3.023834      2.877512  ...       -1.290984                -2.418894\n2     2.980111      3.056357  ...       -1.018047                -2.435203\n3     2.435366      3.014554  ...       -0.409774                -1.754464\n4     3.010128      2.663053  ...       -1.442230                -2.566811\n\n[5 rows x 30 columns]\n\n# Let's plot the data after min-max scaling\nplt.figure(figsize=(10, 6))\nsns.kdeplot(data=df_log)\nplt.title(\"After Log Transformation\")\nplt.show()\n\n\n\n\n\n\n\nZ-score normalization:\nAlso known as standardization, this transformation scales and translates each feature so that it has a mean of 0 and a standard deviation of 1. The transformed data is stored in df_zscore.\nZ-score normalization is a type of data standardization where we convert all features in our dataset to have a mean (µ) of 0 and a standard deviation (σ) of 1. The purpose of this transformation is to remove the scale effect of measurements.\nThe formula for Z-score normalization is:\nZ = (X - µ) / σ\nwhere:\nZ is the standardized (Z-score normalized) value, X is the original value, µ is the mean of the feature, σ is the standard deviation of the feature. Why do we do this? In machine learning, many algorithms (like K-nearest neighbors, Neural Networks, and others) perform better when their input features are roughly on the same scale and centered around zero. If one feature has a range of -1 to 1, while another feature has a range of -1000 to 1000, the second feature will completely dominate when these features are combined, even though the first feature might be just as important.\nAfter Z-score normalization, every feature in the dataset will have a mean of 0 and a standard deviation of 1, putting them all on roughly the same scale. The data values in each column now represent how many standard deviations the original value was from the mean of that column. This makes it easier to compare different features, and helps many machine learning algorithms perform better.\n\n# Z-score normalization\nscaler = preprocessing.StandardScaler()\ndf_zscore = pd.DataFrame(scaler.fit_transform(df), columns=data.feature_names)\nprint(\"\\nAfter Z-score Normalization:\\n\", df_zscore.head())\n\n\nAfter Z-score Normalization:\n    mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n0     1.097064     -2.073335  ...        2.750622                 1.937015\n1     1.829821     -0.353632  ...       -0.243890                 0.281190\n2     1.579888      0.456187  ...        1.152255                 0.201391\n3    -0.768909      0.253732  ...        6.046041                 4.935010\n4     1.750297     -1.151816  ...       -0.868353                -0.397100\n\n[5 rows x 30 columns]\n\n# Let's plot the data after Z-score normalization\nplt.figure(figsize=(10, 6))\nsns.kdeplot(data=df_zscore)\nplt.title(\"After Z-score Normalization\")\nplt.show()\n\n\n\n\n\n\n\nPower transformation (Cube):\nThis transformation raises each value in the DataFrame to the power of 3. It can be used to increase the skewness in the data.\n\n# Power transformation (cube)\ndf_power = df.apply(lambda x: x**3)\nprint(\"\\nAfter Power Transformation:\\n\", df_power.head())\n\n\nAfter Power Transformation:\n    mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n0  5822.285399   1118.386872  ...        0.097399                 0.001681\n1  8703.679193   5611.284433  ...        0.020797                 0.000705\n2  7633.736209   9595.703125  ...        0.047163                 0.000672\n3  1489.355288   8464.718872  ...        0.292490                 0.005178\n4  8353.070389   2948.814504  ...        0.013211                 0.000453\n\n[5 rows x 30 columns]\n\n# Let's plot the data after power transformation\nplt.figure(figsize=(10, 6))\nsns.kdeplot(data=df_power)\nplt.title(\"After Power Transformation\")\nplt.show()\n\n\n\n\n\n\n\nQuantile transformation:\nQuantile transformation, also known as quantile normalization, is a technique for making two distributions identical in statistical properties. To achieve this, it maps the values from the input distribution to a desired output distribution, such as a uniform or a normal distribution.\nThe process can be summarized as follows:\nFor each feature, sort the values in ascending order.\nThe smallest value is replaced with the smallest value from the desired distribution, the second smallest with the second smallest, and so on.\nThis way, the transformed data will have the same distribution as the desired output distribution, while preserving the rank of the original data.\nOne of the main uses of quantile transformation is to reduce the impact of outliers. Because it’s based on the rank of the data, not the actual values, extreme values will be closer to the rest of the data after transformation.\nAnother use is to make non-linear data more suitable for linear models. If a feature has a distribution that’s skewed or has a heavy tail, quantile transformation can help make it more “normal”, so that linear models can make better predictions.\n\n# Quantile transformation\nscaler = preprocessing.QuantileTransformer(output_distribution='normal')\ndf_quantile = pd.DataFrame(scaler.fit_transform(df), columns=data.feature_names)\n\n/Users/l.bravo@bham.ac.uk/Library/r-miniconda-arm64/envs/hds-python/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:2846: UserWarning: n_quantiles (1000) is greater than the total number of samples (569). n_quantiles is set to n_samples.\n  warnings.warn(\n\nprint(\"\\nAfter Quantile Transformation:\\n\", df_quantile.head())\n\n\nAfter Quantile Transformation:\n    mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n0     0.982803     -2.918152  ...        1.966025                 1.618134\n1     1.634697     -0.277117  ...       -0.137235                 0.526427\n2     1.352998      0.513796  ...        1.304975                 0.451806\n3    -0.820429      0.356013  ...        5.199338                 2.918152\n4     1.512992     -1.221674  ...       -1.004493                -0.263385\n\n[5 rows x 30 columns]\n\n# Let's plot the data after quantile transformation\nplt.figure(figsize=(10, 6))\nsns.kdeplot(data=df_quantile)\nplt.title(\"After Quantile Transformation\")\nplt.show()\n\n\n\n\n\n\n\nYour Task",
    "crumbs": [
      "EDA and Pre-Processing",
      "Data Transformation - Python"
    ]
  },
  {
    "objectID": "EDA_Practical3.html#question-1",
    "href": "EDA_Practical3.html#question-1",
    "title": "Data Transformation - Python",
    "section": "Question 1:",
    "text": "Question 1:\n1.1 Load the Bupa Data set and apply Quantile Normalization on each feature.\n1.2 Remove the Label column (\"selector\") from the data set.\n1.3 Visualize the data before and after normalization using boxplot. \nYou can download the dataset through the link:\n\nbupa.csv\n\n\n#df_bupa = pd.read_csv('bupa.csv')\n#df_bupa = df_bupa.dropna()\n\n\n#print(df_bupa)\n\n#print(\"\\Before Quantile Transformation:\\n\")\n# Let's plot the data after quantile transformation\n#plt.figure(figsize=(10, 6))\n#sns.boxplot(data=df_bupa)\n#plt.title(\"After Quantile Transformation\")\n#plt.show()\n\n## ------------------- Complete This ------------------------- ##\n## scaler = preprocessing. ... \n## df_bupa_quantile = pd.DataFrame(scaler.fit_transform( ... ), columns =  ... )\n\n#print(\"\\nAfter Quantile Transformation:\\n\")\n## Let's plot the data after quantile transformation\n#plt.figure(figsize=(10, 6))\n#sns.boxplot(data=df_bupa_quantile)\n#plt.title(\"After Quantile Transformation\")\n#plt.show()",
    "crumbs": [
      "EDA and Pre-Processing",
      "Data Transformation - Python"
    ]
  },
  {
    "objectID": "MissingPackages.html",
    "href": "MissingPackages.html",
    "title": "",
    "section": "",
    "text": "Code",
    "crumbs": [
      "EDA and Pre-Processing",
      "Missing Pipelines in R"
    ]
  },
  {
    "objectID": "MissingPackages.html#missing-pipelines-in-r",
    "href": "MissingPackages.html#missing-pipelines-in-r",
    "title": "",
    "section": "Missing Pipelines in R",
    "text": "Missing Pipelines in R\nAs with the correlation matrices before, there are really good packages to help you understand the missingness structure of your data. This is my recommendation:\n\nlibrary(naniar)\nlibrary(finalfit)\nlibrary(ggplot2)\nlibrary(mice)\n\n\nAttaching package: 'mice'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following objects are masked from 'package:base':\n\n    cbind, rbind\n\n\nHere I will be using the airquality dataset (available as default in all R) but everything would be ready for you to introduce your own dataset in a future.\n\nsummary(airquality)\n\n     Ozone           Solar.R           Wind             Temp      \n Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00  \n 1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00  \n Median : 31.50   Median :205.0   Median : 9.700   Median :79.00  \n Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88  \n 3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00  \n Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00  \n NA's   :37       NA's   :7                                       \n     Month            Day      \n Min.   :5.000   Min.   : 1.0  \n 1st Qu.:6.000   1st Qu.: 8.0  \n Median :7.000   Median :16.0  \n Mean   :6.993   Mean   :15.8  \n 3rd Qu.:8.000   3rd Qu.:23.0  \n Max.   :9.000   Max.   :31.0  \n                               \n\n\nWe can already see with a simple summary, the ammount of missings we have per column. But what is their underlyng structure?\n\nYourDataset &lt;- airquality\n\nPlot 1\n\nll &lt;- data.frame(is.na(YourDataset))\n\nOpen up this ll object. What are you seeing here? is.na() detects all values coded as NA and gives a logical output, TRUE if truly a missing value and FALSE if not\n\nView(ll)\n\n\ncols &lt;- sapply(ll, is.logical)\nll[, cols] &lt;- lapply(ll[, cols], as.numeric)\n\nMiss1 &lt;- UpSetR::upset(ll,\n                       nsets = 20, number.angles = 10, point.size = 3.5, line.size = 2,\n                       mainbar.y.label = \"Missing Values\", sets.x.label = \"Total Number Missing Values\",\n                       text.scale = c(2.3, 2.3, 2, 2, 2, 1.75), order.by = \"freq\", sets.bar.color = \"red3\"\n)\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\nℹ The deprecated feature was likely used in the UpSetR package.\n  Please report the issue to the authors.\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\nℹ The deprecated feature was likely used in the UpSetR package.\n  Please report the issue to the authors.\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\nℹ The deprecated feature was likely used in the UpSetR package.\n  Please report the issue to the authors.\n\nMiss1\n\n\n\n\n\n\n\nHere we can see common patterns! If missing values were to happen at the same time in different variables, we would see it clearly. Lets store this figure into our own directories so we can then use it for our final research output!\n\npdf(\"MissingVal1.pdf\", 10, 20)\nprint(Miss1)\ndev.off()\n\nquartz_off_screen \n                2",
    "crumbs": [
      "EDA and Pre-Processing",
      "Missing Pipelines in R"
    ]
  },
  {
    "objectID": "HistogramBoxplot.html",
    "href": "HistogramBoxplot.html",
    "title": "",
    "section": "",
    "text": "Code",
    "crumbs": [
      "EDA and Pre-Processing",
      "Histograms and Boxplots"
    ]
  },
  {
    "objectID": "HistogramBoxplot.html#histograms-and-boxplots",
    "href": "HistogramBoxplot.html#histograms-and-boxplots",
    "title": "",
    "section": "Histograms and Boxplots",
    "text": "Histograms and Boxplots\nHistograms show the overall shape and spread of the data distribution and box plots summarise key statistics (median, spread, and potential outliers) and are particularly helpful for comparing distributions across groups.\nSummary Statistics\n\nlibrary(ggplot2)\n\n\n# Example data\ndata &lt;- data.frame(age = c(2,  45, 56, 47, 67, 67, 68, 72, 75, 80, 85,86, 89,125))\nhead(data)\n\n  age\n1   2\n2  45\n3  56\n4  47\n5  67\n6  67\n\n\nWhat is the distribution of the age data? What are the mean, median and standard deviation?\n\nMean &lt;- mean(data$age)\nMedian &lt;- median(data$age)\nSd &lt;- sd(data$age)\n\nOther data distribution descriptors include quantiles, which divide data into equal-sized intervals:\n0% (Minimum) 25% (Q1, First Quartile) 50% (Median, Second Quartile) 75% (Q3, Third Quartile) *100% (Maximum)\n\nQuantile &lt;- quantile(data$age)\nQuantile\n\n    0%    25%    50%    75%   100% \n  2.00  58.75  70.00  83.75 125.00 \n\n\nThe IQR (Interquartile Range) measures the spread of the middle 50% of your data.\nIf you look at the Quantile results above, you can calculate it from \\(IQR=Q3−Q1\\), where Q3 is the value beyond which 75% of your data lies. What is then Q2? The value beyond which 25% of your data lies.\n\nIQR &lt;- IQR(data$age)\nIQR\n\n[1] 25\n\n\nCan do it in a single go:\n\nsummary(data$age) \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.00   58.75   70.00   68.86   83.75  125.00 \n\n\nAs we saw, lots of different datasets can end up with these summary statistics, so lets plot it to get real insight about what is happening:",
    "crumbs": [
      "EDA and Pre-Processing",
      "Histograms and Boxplots"
    ]
  },
  {
    "objectID": "HistogramBoxplot.html#histogram-in-r",
    "href": "HistogramBoxplot.html#histogram-in-r",
    "title": "",
    "section": "Histogram in R",
    "text": "Histogram in R\nA histogram is a way to visualise the frequency distribution of a dataset. It groups data into bins and shows how many data points fall into each bin\n\nggplot(data, aes(x = age)) + \n  geom_histogram() \n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\nYou can modify the binwidth parameter, what is happening here?\n\nggplot(data, aes(x = age)) + \n  geom_histogram(binwidth = 30) \n\n\n\n\n\n\n\nNow lets go back t original and add the mean and median\n\nggplot(data, aes(x = age)) + \n  geom_histogram() +\n  geom_vline(xintercept = Mean, color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_vline(xintercept = Median, color = \"blue\", linetype = \"dashed\", size = 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\nIf do not remember how ggplot works , here is a cheatsheet: https://rstudio.github.io/cheatsheets/html/data-visualization.html\nIn summary, a histogram helps you understand the shape of your data distribution (e.g., normal, skewed) and peaks indicate the most frequent values.",
    "crumbs": [
      "EDA and Pre-Processing",
      "Histograms and Boxplots"
    ]
  },
  {
    "objectID": "HistogramBoxplot.html#box-plot-in-r",
    "href": "HistogramBoxplot.html#box-plot-in-r",
    "title": "",
    "section": "Box Plot in R",
    "text": "Box Plot in R\nA box plot (or box-and-whisker plot) summarises the distribution of a dataset. It highlights:\n\nMedian (middle line in the box).\nQuantiles (the box spans from the 25th percentile to the 75th percentile)\nIQR (Interquartile Range): The difference between the 75th and 25th percentiles - (IQR range calculated above)\nWhiskers: Extend to data points within 1.5*IQR (above or beyond = outliers)\n\n\nggplot(data, aes(x = age)) + \n  geom_boxplot() + \n  coord_flip() #have you checked what this does? Take it out and see\n\n\n\n\n\n\n\nCan you see summary statistics mapped here?\nLets plot the mean (as it is a value that is not reflected in a boxplot!)\n\nggplot(data, aes(x = age)) + \n  geom_boxplot() + \n  coord_flip() + \n   geom_vline(xintercept = Mean, color = \"blue\", linetype = \"dashed\", size = 1) \n\n\n\n\n\n\n\nBit more advanced! (add another geom layer, in this case geom_jitter. What does it do? How is it different from geom_point?)\n\n# Load ggplot2\nlibrary(ggplot2)\n\n# Sample data\nset.seed(123)\ndata &lt;- data.frame(\n  Group = rep(c(\"A\", \"B\", \"C\"), each = 200),\n  Value = c(rnorm(200, mean = 5, sd = 1), \n            rnorm(200, mean = 6, sd = 1.2), \n            rnorm(200, mean = 7, sd = 1.5))\n)\n\n# Combined Plot\np1 &lt;- ggplot(data, aes(x = Group, y = Value, fill = Group)) +\n  # Violin + Boxplot + Jitter\n  geom_boxplot(width = 0.2, outlier.color = \"red\", outlier.size = 2, colour = \"black\") +\n  geom_jitter(position = position_jitter(0.2), color = \"black\", alpha = 0.4) + #scatter plot but in random positions, check geom_point() and see\n  labs(title = \"Boxplot and Violin Plot with Jitter\", x = \"Groups\", y = \"Values\") +\n  theme_minimal()\n\np2 &lt;- ggplot(data, aes(x = Value, fill = Group)) +\n  # Histogram\n  geom_histogram(alpha = 0.6, position = \"identity\", binwidth = 0.3, colour = \"black\") +\n  labs(title = \"Histogram of Values by Group\", x = \"Values\", y = \"Count\") +\n  theme_minimal()\n\n\n# Display both plots side by side\nlibrary(patchwork)\np1 + p2\n\n\n\n\n\n\n\n\n# Display both plots up down\nlibrary(patchwork)\np1 / p2\n\n\n\n\n\n\n\nAlso, maybe we want to understand how the distribution varies by more groups. We can use facets:\n\nlibrary(gapminder)\n\n# Box plot with facets by year\nggplot(gapminder, aes(x = continent, y = lifeExp, fill = continent)) +\n  geom_boxplot() +\n  facet_wrap(~ year) +  # Create facets for each year\n  labs(title = \"Life Expectancy Across Continents by Year\",\n       x = \"Continent\",\n       y = \"Life Expectancy\") +\n  theme_minimal() + #just to make it nice\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels - just to make it nice\n\n\n\n\n\n\n\nWhat is happening here? View (gapminder) dataset. If we focus on 1952 year, extract the necessary values to create the boxplot for Africa.\n\n#for example \nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.2.0     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nSubgroup &lt;- gapminder %&gt;% \n  filter(year == \"1952\") %&gt;%\n  filter(continent == \"Africa\")\n#data wrangling - can learn more from Introduction exercise on data wrangling\n\nMedian &lt;- median(Subgroup$lifeExp)\n\nMedian\n\n[1] 38.833\n\n\nDoes it match the plot? Continue with the rest of parameters (IQR, mean, quantile)",
    "crumbs": [
      "EDA and Pre-Processing",
      "Histograms and Boxplots"
    ]
  },
  {
    "objectID": "Correlation.html",
    "href": "Correlation.html",
    "title": "",
    "section": "",
    "text": "Code",
    "crumbs": [
      "EDA and Pre-Processing",
      "Correlation - R"
    ]
  },
  {
    "objectID": "Correlation.html#correlation---r",
    "href": "Correlation.html#correlation---r",
    "title": "",
    "section": "Correlation - R",
    "text": "Correlation - R\nAs you have learnt throughout these modules, Python and R offer packages and libraries that contain already predefined functions ready to implement into your code. For you to see the breadth of possibilities out there, here is an example of different ways in whcih to describe and learn about the correlation matrix of your dataset.\n\n# Install required libraries (if not already installed)\n#install.packages(c(\"ggplot2\", \"corrplot\", \"ggcorrplot\", \"PerformanceAnalytics\", \"GGally\", \"psych\", \"corrr\"))\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(corrplot)\nlibrary(ggcorrplot)\nlibrary(PerformanceAnalytics)\nlibrary(GGally)\nlibrary(psych)\nlibrary(corrr)\n\nTo assess the association between two variables, you can produce a scatter plot like below:\n\nset.seed(123)\nx &lt;- rnorm(100)\ny &lt;- x + rnorm(100, sd = 0.5)\n\nggplot(data = data.frame(x, y), aes(x = x, y = y)) +\n  geom_point(color = \"blue\", size = 2) +\n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n  labs(title = \"Correlation Plot with ggplot2\",\n       x = \"X values\", y = \"Y values\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nNow we are going to produce the correlation matrix, where in a go, you get insight of all the association happening in your dataset.For this we are going to use the mtcars data (A built-in dataset that contains measurements on 11 different attributes for 32 different cars). More specifically, the chosen variables are:\n\nmpg (Miles per Gallon): Represents the fuel efficiency of the car. Higher values, better efficiency.\ndisp (Displacement): Represents the engine displacement, which is the total volume of all the cylinders in the engine.\nhp (Horsepower): Represents the power output of the car’s engine.\nwt (Weight): Represents the weight of the car.\n\n\ndata &lt;- mtcars[, c(\"mpg\", \"disp\", \"hp\", \"wt\")]\n\nBut first, produce plots of all the two variable associations combinations in the features studied c(\"mpg\", \"disp\", \"hp\", \"wt\"). How many plots do you need?\nCan you calculate the correlation between them? Remember there are different ways in which to calculate correlation https://www.sthda.com/english/wiki/correlation-test-between-two-variables-in-r and you can specify the type in your code cor(x, y, method = c(\"pearson\", \"kendall\", \"spearman\"))\nNow that you know what to expect, lets proceed with the correlation matrices (same thing as above, but all in a go!):\n—–corrplot Correlation Matrix —–\n\ncor_matrix &lt;- cor(data)\ncorrplot(cor_matrix, method = \"circle\", type = \"upper\", \n         title = \"Correlation Matrix\", addCoef.col = \"black\")\n\n\n\n\n\n\n\n—–corrplot Correlation Matrix —–\n\nggcorrplot(cor_matrix, \n           method = \"square\", \n           type = \"lower\", \n           lab = TRUE, \n           title = \"mtcars\", \n           lab_size = 3) +\n  theme_minimal()\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\nℹ The deprecated feature was likely used in the ggcorrplot package.\n  Please report the issue at &lt;https://github.com/kassambara/ggcorrplot/issues&gt;.\n\n\n\n\n\n\n\n\n—–PerformanceAnalytics Pairwise Correlation Plot —–\n\nchart.Correlation(data, histogram = TRUE, pch = 19)\n\n\n\n\n\n\n\n###—–GGally Pairwise Correlation Plot —–\n\nggpairs(data, \n        title = \"Pairwise Correlation Plot with GGally\",\n        lower = list(continuous = wrap(\"smooth\", method = \"lm\")),\n        upper = list(continuous = wrap(\"cor\", size = 3)))\n\n\n\n\n\n\n\n###—– psych Enhanced Pairwise Correlation Plot —–\n\npairs.panels(data, \n             method = \"pearson\", \n             hist.col = \"lightblue\", \n             density = TRUE, \n             ellipses = TRUE)\n\n\n\n\n\n\n\n###—– Base R Heatmap —–\n\n# ----- 8. Base R Heatmap -----\nheatmap(cor_matrix, symm = TRUE, \n        main = \"Correlation Heatmap\", \n        col = colorRampPalette(c(\"red\", \"white\", \"blue\"))(20))\n\n\n\n\n\n\n\n\n# ----- 10. corrr Tidy Correlation -----\ncor_matrix_tidy &lt;- correlate(data)\n\nCorrelation computed with\n• Method: 'pearson'\n• Missing treated using: 'pairwise.complete.obs'\n\ncor_matrix_tidy %&gt;% \n  fashion() %&gt;% \n  print()\n\n  term  mpg disp   hp   wt\n1  mpg      -.85 -.78 -.87\n2 disp -.85       .79  .89\n3   hp -.78  .79       .66\n4   wt -.87  .89  .66     \n\n# Network-style correlation plot\ncor_matrix_tidy %&gt;% \n  network_plot(min_cor = 0.3)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\nℹ The deprecated feature was likely used in the corrr package.\n  Please report the issue at &lt;https://github.com/tidymodels/corrr/issues&gt;.\n\n\n\n\n\n\n\n\nWhat are your insights? Do they make sense? Remember:\n\nmpg (Miles per Gallon): Represents the fuel efficiency of the car. Higher values, better efficiency.\ndisp (Displacement): Represents the engine displacement, which is the total volume of all the cylinders in the engine.\nhp (Horsepower): Represents the power output of the car’s engine.\nwt (Weight): Represents the weight of the car.",
    "crumbs": [
      "EDA and Pre-Processing",
      "Correlation - R"
    ]
  },
  {
    "objectID": "EDA_Practical1_Final.html",
    "href": "EDA_Practical1_Final.html",
    "title": "Missing Data Imputation - Python",
    "section": "",
    "text": "library(reticulate)\n\n# one-off setup (if you haven't done it yet)\n# install_miniconda()\n\n##conda_create(\n##  envname = \"hds-python\",\n##  python_version = \"3.11\",\n##  packages = c(\"numpy\", \"pandas\", \"matplotlib\", \"seaborn\", \"scikit-learn\")\n##)\n\nuse_condaenv(\"hds-python\", required = TRUE)\n#py_config()\n\n#conda_install(\"hds-python\", c(\"jupyter\", \"plotly\"))",
    "crumbs": [
      "EDA and Pre-Processing",
      "Missing Data Imputation - Python"
    ]
  },
  {
    "objectID": "EDA_Practical1_Final.html#dummy-variables",
    "href": "EDA_Practical1_Final.html#dummy-variables",
    "title": "Missing Data Imputation - Python",
    "section": "Dummy variables",
    "text": "Dummy variables\nAs well as imputation we are interested in other transformations. For example, hot encoding categorical data. For extra insight https://www.kaggle.com/code/marcinrutecki/one-hot-encoding-everything-you-need-to-know\n\nX_reduced_Encoder = heart_df.loc[:, ['chol', 'thalach','sex','cp']]\nX_reduced_Encoder[categorical_features] = X_reduced_Encoder[categorical_features].astype('category')\n\n# Apply OneHotEncoder\nencoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\nencoded_categorical = encoder.fit_transform(X_reduced_Encoder[categorical_features])\n\n\nencoded_df = pd.DataFrame(\n    encoded_categorical,\n    columns=encoder.get_feature_names_out(categorical_features)\n)\n\n\n# Combine the encoded features with the original dataset (drop original categorical columns)\nvisualised_df = pd.concat([X_reduced_Encoder.drop(columns=categorical_features), encoded_df], axis=1)\nprint(visualised_df)\n\n     chol  thalach  sex_0.0  sex_1.0  ...  cp_2.0  cp_3.0  cp_4.0  cp_nan\n0    60.0     12.0      0.0      1.0  ...     0.0     0.0     1.0     0.0\n1     NaN      8.0      0.0      1.0  ...     0.0     0.0     1.0     0.0\n2    27.0     19.0      0.0      1.0  ...     0.0     0.0     1.0     0.0\n3    39.0     25.0      0.0      1.0  ...     0.0     0.0     1.0     0.0\n4    22.0     53.0      0.0      1.0  ...     0.0     1.0     0.0     0.0\n..    ...      ...      ...      ...  ...     ...     ...     ...     ...\n195  95.0      NaN      1.0      0.0  ...     0.0     0.0     1.0     0.0\n196  30.0      1.0      0.0      1.0  ...     0.0     0.0     0.0     0.0\n197  33.0      4.0      0.0      1.0  ...     0.0     0.0     1.0     0.0\n198   3.0      1.0      0.0      1.0  ...     0.0     0.0     0.0     1.0\n199   NaN     47.0      0.0      1.0  ...     1.0     0.0     0.0     0.0\n\n[200 rows x 10 columns]\n\n\nAs you have seen we have gone back to original data so one of the new columns created is nan! To circumvent this apply this to a dataframe AFTER imputation!!!\n\n\n#Impute dataset and then do the hot encoding: \n\nCheck out the concept of Pipeline https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html when do you think it can come in handy?",
    "crumbs": [
      "EDA and Pre-Processing",
      "Missing Data Imputation - Python"
    ]
  },
  {
    "objectID": "pima_leakage_pipeline.html",
    "href": "pima_leakage_pipeline.html",
    "title": "Pima Preprocessing → Leak-free ML Pipeline (R)",
    "section": "",
    "text": "Codelibrary(tidyverse)\nlibrary(janitor)\nlibrary(tidymodels)\n\ntheme_set(theme_minimal())\nset.seed(123)",
    "crumbs": [
      "EDA and Pre-Processing",
      "Pima Preprocessing → Leak-free ML Pipeline (R)"
    ]
  },
  {
    "objectID": "pima_leakage_pipeline.html#data-and-goal",
    "href": "pima_leakage_pipeline.html#data-and-goal",
    "title": "Pima Preprocessing → Leak-free ML Pipeline (R)",
    "section": "1. Data and goal",
    "text": "1. Data and goal\nWe will use the PimaIndiansDiabetes2 dataset and focus on a simple regression problem:\n\n\nOutcome: pedigree (diabetes pedigree function)\n\n\nPredictors: age, glucose\n\n\nOur goal is to compare two pipelines:\n\nA wrong one, where we scale before splitting (data leakage).\nA correct one, where we scale using training data only.\n\nWe’ll use MAE (Mean Absolute Error) to compare test performance.\n\nCodedata(\"PimaIndiansDiabetes2\", package = \"mlbench\")\n\npima_small &lt;- PimaIndiansDiabetes2 %&gt;%\n  clean_names() %&gt;%\n  select(age, glucose, pedigree) %&gt;%\n  filter(!is.na(pedigree))  # outcome must be present\n\nhead(pima_small)\n\n  age glucose pedigree\n1  50     148    0.627\n2  31      85    0.351\n3  32     183    0.672\n4  21      89    0.167\n5  33     137    2.288\n6  30     116    0.201\n\nCodesummary(pima_small)\n\n      age           glucose         pedigree     \n Min.   :21.00   Min.   : 44.0   Min.   :0.0780  \n 1st Qu.:24.00   1st Qu.: 99.0   1st Qu.:0.2437  \n Median :29.00   Median :117.0   Median :0.3725  \n Mean   :33.24   Mean   :121.7   Mean   :0.4719  \n 3rd Qu.:41.00   3rd Qu.:141.0   3rd Qu.:0.6262  \n Max.   :81.00   Max.   :199.0   Max.   :2.4200  \n                 NA's   :5",
    "crumbs": [
      "EDA and Pre-Processing",
      "Pima Preprocessing → Leak-free ML Pipeline (R)"
    ]
  },
  {
    "objectID": "pima_leakage_pipeline.html#wrong-pipeline-scaling-before-traintest-split-leakage",
    "href": "pima_leakage_pipeline.html#wrong-pipeline-scaling-before-traintest-split-leakage",
    "title": "Pima Preprocessing → Leak-free ML Pipeline (R)",
    "section": "2. WRONG pipeline: scaling before train–test split (leakage)",
    "text": "2. WRONG pipeline: scaling before train–test split (leakage)\n2.1. Compute global mean and sd (leaky)\n\nCodemean_all_glucose &lt;- mean(pima_small$glucose, na.rm = TRUE)\nsd_all_glucose   &lt;- sd(pima_small$glucose, na.rm = TRUE)\n\nmean_all_age &lt;- mean(pima_small$age, na.rm = TRUE)\nsd_all_age   &lt;- sd(pima_small$age, na.rm = TRUE)\n\nmean_all_glucose; sd_all_glucose\n\n[1] 121.6868\n\n\n[1] 30.53564\n\nCodemean_all_age; sd_all_age\n\n[1] 33.24089\n\n\n[1] 11.76023\n\n\n2.2. Scale the full dataset using global statistics\n\nCodepima_small_scaled &lt;- pima_small %&gt;%\n  mutate(\n    glucose_scaled = (glucose - mean_all_glucose) / sd_all_glucose,\n    age_scaled     = (age - mean_all_age) / sd_all_age\n  )\n\nhead(pima_small_scaled)\n\n  age glucose pedigree glucose_scaled  age_scaled\n1  50     148    0.627      0.8617221  1.42506672\n2  31      85    0.351     -1.2014407 -0.19054773\n3  32     183    0.672      2.0079237 -0.10551539\n4  21      89    0.167     -1.0704463 -1.04087112\n5  33     137    2.288      0.5014873 -0.02048305\n6  30     116    0.201     -0.1862336 -0.27558007\n\n\n2.3. Train–test split on already scaled data\n\nCodeset.seed(123)\ndata_split &lt;- initial_split(pima_small_scaled, prop = 0.7)\n\ntrain &lt;- training(data_split)\ntest  &lt;- testing(data_split)\n\nnrow(train); nrow(test)\n\n[1] 537\n\n\n[1] 231\n\n\n2.4. Fit linear regression model and compute MAE (WRONG)\n\nCodeped_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\nfit_wrong &lt;- ped_model %&gt;%\n  fit(pedigree ~ age_scaled + glucose_scaled, data = train)\n\nresults_wrong &lt;- predict(fit_wrong, new_data = test) %&gt;%\n  bind_cols(test)\n\nmae_wrong &lt;- mae(\n  data    = results_wrong,\n  truth   = pedigree,\n  estimate = .pred\n)\n\nmae_wrong\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 mae     standard       0.234",
    "crumbs": [
      "EDA and Pre-Processing",
      "Pima Preprocessing → Leak-free ML Pipeline (R)"
    ]
  },
  {
    "objectID": "pima_leakage_pipeline.html#right-pipeline-scaling-using-training-data-only-no-leakage",
    "href": "pima_leakage_pipeline.html#right-pipeline-scaling-using-training-data-only-no-leakage",
    "title": "Pima Preprocessing → Leak-free ML Pipeline (R)",
    "section": "3. RIGHT pipeline: scaling using training data only (no leakage)",
    "text": "3. RIGHT pipeline: scaling using training data only (no leakage)\n3.1. Train–test split on the original data\n\nCodeset.seed(123)\ndata_split_right &lt;- initial_split(pima_small, prop = 0.8)\n\ntrain &lt;- training(data_split_right)\ntest  &lt;- testing(data_split_right)\n\nnrow(train); nrow(test)\n\n[1] 614\n\n\n[1] 154\n\n\n3.2. Compute training-only mean and sd\n\nCodemu_tr_glucose &lt;- mean(train$glucose, na.rm = TRUE)\nsd_tr_glucose &lt;- sd(train$glucose, na.rm = TRUE)\n\nmu_tr_age &lt;- mean(train$age, na.rm = TRUE)\nsd_tr_age &lt;- sd(train$age, na.rm = TRUE)\n\nmu_tr_glucose; sd_tr_glucose\n\n[1] 122.2902\n\n\n[1] 30.25447\n\nCodemu_tr_age; sd_tr_age\n\n[1] 33.1759\n\n\n[1] 11.81636\n\n\n3.3. Scale train and test using training statistics\n\nCodetrain_scaled &lt;- train %&gt;%\n  mutate(\n    glucose_scaled = (glucose - mu_tr_glucose) / sd_tr_glucose,\n    age_scaled     = (age - mu_tr_age)     / sd_tr_age\n  )\n\ntest_scaled &lt;- test %&gt;%\n  mutate(\n    glucose_scaled = (glucose - mu_tr_glucose) / sd_tr_glucose,\n    age_scaled     = (age - mu_tr_age)     / sd_tr_age\n  )\n\nhead(train_scaled)\n\n    age glucose pedigree glucose_scaled age_scaled\n415  21     138    0.534      0.5192568 -1.0304267\n463  39      74    0.705     -1.5961334  0.4928847\n179  47     143    0.190      0.6845216  1.1699120\n526  21      87    0.444     -1.1664448 -1.0304267\n195  42      85    0.136     -1.2325507  0.7467699\n118  25      78    0.654     -1.4639215 -0.6919131\n\nCodehead(test_scaled)\n\n   age glucose pedigree glucose_scaled  age_scaled\n1   50     148    0.627      0.8497865  1.42379718\n3   32     183    0.672      2.0066404 -0.09951419\n9   53     197    0.158      2.4693820  1.67768241\n17  31     118    0.551     -0.1418027 -0.18414260\n22  50      99    0.388     -0.7698091  1.42379718\n27  43     147    0.257      0.8167335  0.83139832\n\n\n3.4. Fit linear regression model and compute MAE (RIGHT)\n\nCodeped_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\nfit_right &lt;- ped_model %&gt;%\n  fit(pedigree ~ age_scaled + glucose_scaled, data = train_scaled)\n\nresults_right &lt;- predict(fit_right, new_data = test_scaled) %&gt;%\n  bind_cols(test_scaled)\n\nmae_right &lt;- mae(\n  data    = results_right,\n  truth   = pedigree,\n  estimate = .pred\n)\n\nmae_right\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 mae     standard       0.234",
    "crumbs": [
      "EDA and Pre-Processing",
      "Pima Preprocessing → Leak-free ML Pipeline (R)"
    ]
  },
  {
    "objectID": "pima_leakage_pipeline.html#comparing-mae-leaky-vs-leak-free",
    "href": "pima_leakage_pipeline.html#comparing-mae-leaky-vs-leak-free",
    "title": "Pima Preprocessing → Leak-free ML Pipeline (R)",
    "section": "4. Comparing MAE: leaky vs leak-free",
    "text": "4. Comparing MAE: leaky vs leak-free\n\nCodetibble(\n  pipeline = c(\"WRONG: scaled before split (leakage)\",\n               \"RIGHT: scaled using training only\"),\n  MAE = c(mae_wrong$.estimate,\n          mae_right$.estimate)\n)\n\n# A tibble: 2 × 2\n  pipeline                               MAE\n  &lt;chr&gt;                                &lt;dbl&gt;\n1 WRONG: scaled before split (leakage) 0.234\n2 RIGHT: scaled using training only    0.234",
    "crumbs": [
      "EDA and Pre-Processing",
      "Pima Preprocessing → Leak-free ML Pipeline (R)"
    ]
  },
  {
    "objectID": "pima_preprocessing_sklearn_python.html",
    "href": "pima_preprocessing_sklearn_python.html",
    "title": "Pima – Imputation & Scaling with scikit-learn (Python)",
    "section": "",
    "text": "This document shows how to perform mean imputation and standardisation correctly in Python using scikit-learn, first manually and then using a Pipeline.\nWe load the same Pima Indians database and select the following columns:\nCodeimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer",
    "crumbs": [
      "EDA and Pre-Processing",
      "Pima – Imputation & Scaling with scikit-learn (Python)"
    ]
  },
  {
    "objectID": "pima_preprocessing_sklearn_python.html#example-data-placeholder",
    "href": "pima_preprocessing_sklearn_python.html#example-data-placeholder",
    "title": "Pima – Imputation & Scaling with scikit-learn (Python)",
    "section": "1. Example data (placeholder)",
    "text": "1. Example data (placeholder)\nReplace this with your real data load. Here we just create a tiny artificial example so the code runs.\n\nCode\n\nurl=\"https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv\"\ndf = pd.read_csv(url)\n\ndf.columns = df.columns.str.lower()\ndf = df.rename(columns={\"diabetespedigreefunction\": \"pedigree\"})\n\n\nfeatures = [\"age\", \"glucose\", \"insulin\"]\ndf[features] = df[features].replace(0, np.nan)\nX = df[features]\ny = df[\"pedigree\"]",
    "crumbs": [
      "EDA and Pre-Processing",
      "Pima – Imputation & Scaling with scikit-learn (Python)"
    ]
  },
  {
    "objectID": "pima_preprocessing_sklearn_python.html#manual-preprocessing-impute-scale-no-pipeline",
    "href": "pima_preprocessing_sklearn_python.html#manual-preprocessing-impute-scale-no-pipeline",
    "title": "Pima – Imputation & Scaling with scikit-learn (Python)",
    "section": "2. Manual preprocessing: impute + scale (no Pipeline)",
    "text": "2. Manual preprocessing: impute + scale (no Pipeline)\nHere we explicitly:\n\nSplit into train and test.\nFit SimpleImputer on the training set and transform train & test.\nFit StandardScaler on the training set and transform train & test.\nFit a LinearRegression model and compute MAE on the test set.\n\n\nCode\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=123\n)\n\n# 1. Mean imputation (TRAIN only)\nimputer = SimpleImputer(strategy=\"mean\")\nX_train_imp = imputer.fit_transform(X_train)   # learns means from TRAIN\nX_test_imp  = imputer.transform(X_test)        # applies TRAIN means\n\n# 2. Standardisation (TRAIN only)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_imp)  # learns μ, σ from TRAIN\nX_test_scaled  = scaler.transform(X_test_imp)       # uses TRAIN μ, σ\n\n\n\nCode# 3. Linear regression on preprocessed data\nmodel = LinearRegression()\nmodel.fit(X_train_scaled, y_train)\n\n\n\n\nLinearRegression()\nIn a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n\n\nLinearRegression\n\n?Documentation for LinearRegressioniFitted\n\n        \n            Parameters\n\n\nfit_intercept \nTrue\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n    \n\n\n\n\nCodey_pred = model.predict(X_test_scaled)\nmae_manual = mean_absolute_error(y_test, y_pred)\nmae_manual\n\n0.24771496683579874",
    "crumbs": [
      "EDA and Pre-Processing",
      "Pima – Imputation & Scaling with scikit-learn (Python)"
    ]
  },
  {
    "objectID": "pima_preprocessing_sklearn_python.html#using-a-scikit-learn-pipeline-cleanest-version",
    "href": "pima_preprocessing_sklearn_python.html#using-a-scikit-learn-pipeline-cleanest-version",
    "title": "Pima – Imputation & Scaling with scikit-learn (Python)",
    "section": "3. Using a scikit-learn Pipeline (cleanest version)",
    "text": "3. Using a scikit-learn Pipeline (cleanest version)\nPipelines package preprocessing + model into a single object:\n\nImputation and scaling are still fit on the training data only.\nThe same transformations are automatically applied to any new data.\n\n\nCodenumeric_features = [\"age\", \"glucose\", \"insulin\"]\n\nnumeric_transformer = Pipeline(\n    steps=[\n        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n        (\"scaler\", StandardScaler()),\n    ]\n)\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, numeric_features)\n    ]\n)\n\nmodel = LinearRegression()\n\npipe = Pipeline(\n    steps=[\n        (\"preprocess\", preprocess),\n        (\"model\", model),\n    ]\n)\n\nX = df[numeric_features]\ny = df[\"pedigree\"]\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=123\n)\n\npipe.fit(X_train, y_train)\n\n\n\n\nPipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer()),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  ['age', 'glucose',\n                                                   'insulin'])])),\n                ('model', LinearRegression())])\nIn a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n\n\n\nPipeline\n\n?Documentation for PipelineiFitted\n\n        \n            Parameters\n\n\nsteps \n[('preprocess', ...), ('model', ...)]\n\n\n\ntransform_input \nNone\n\n\n\nmemory \nNone\n\n\n\nverbose \nFalse\n\n\n\n    \n\n\n\n\npreprocess: ColumnTransformer\n?Documentation for preprocess: ColumnTransformer\n        \n            Parameters\n\n\ntransformers \n[('num', ...)]\n\n\n\nremainder \n'drop'\n\n\n\nsparse_threshold \n0.3\n\n\n\nn_jobs \nNone\n\n\n\ntransformer_weights \nNone\n\n\n\nverbose \nFalse\n\n\n\nverbose_feature_names_out \nTrue\n\n\n\nforce_int_remainder_cols \n'deprecated'\n\n\n\n    \n\n\n\nnum['age', 'glucose', 'insulin']\n\n\n\nSimpleImputer\n?Documentation for SimpleImputer\n        \n            Parameters\n\n\nmissing_values \nnan\n\n\n\nstrategy \n'mean'\n\n\n\nfill_value \nNone\n\n\n\ncopy \nTrue\n\n\n\nadd_indicator \nFalse\n\n\n\nkeep_empty_features \nFalse\n\n\n\n    \n\n\nStandardScaler\n?Documentation for StandardScaler\n        \n            Parameters\n\n\ncopy \nTrue\n\n\n\nwith_mean \nTrue\n\n\n\nwith_std \nTrue\n\n\n\n    \n\n\n\n\n\nLinearRegression\n?Documentation for LinearRegression\n        \n            Parameters\n\n\nfit_intercept \nTrue\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n    \n\n\n\n\n\n\nCodey_pred_pipe = pipe.predict(X_test)\n\nmae_pipe = mean_absolute_error(y_test, y_pred_pipe)\nmae_pipe\n\n0.24771496683579874\n\n\n\nCodeprint(\"MAE (manual preprocessing):\", mae_manual)\n\nMAE (manual preprocessing): 0.24771496683579874\n\nCodeprint(\"MAE (Pipeline):           \", mae_pipe)\n\nMAE (Pipeline):            0.24771496683579874\n\n\nIn practice, you should prefer the Pipeline approach:\n\nlower risk of mistakes,\neasy extension to cross-validation and more complex models.",
    "crumbs": [
      "EDA and Pre-Processing",
      "Pima – Imputation & Scaling with scikit-learn (Python)"
    ]
  }
]